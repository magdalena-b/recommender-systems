{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorium 3 - wieloręcy bandyci\n",
    "\n",
    "## Przygotowanie\n",
    "\n",
    " * [opcjonalnie] Utwórz wirtualne środowisko\n",
    " `python3 -m venv ./recsyslab3`\n",
    " * zainstaluj potrzebne biblioteki:\n",
    " `pip install matplotlib`\n",
    " * upewnij się, że plik `bandit_framework.py` najduje się w tym samym katalogu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 1. - framework i naiwni bandyci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importujemy wszystkie potrzebne pakiety\n",
    "\n",
    "from copy import copy\n",
    "from math import log, sqrt\n",
    "from random import betavariate, normalvariate, random, sample, shuffle, uniform\n",
    "from bandit_framework import * # w tym pakiet ze srodowiskiem testowym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicjalizujemy parametry testu\n",
    "\n",
    "arms_number = 50\n",
    "runs = 50\n",
    "epochs = 1440\n",
    "recommendation_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicjalizujemy ramiona bandytow - payout kazdego ramienia bedzie reprezentowany przez rozklad normalny\n",
    "\n",
    "arms = {}\n",
    "for i in range(50):\n",
    "    activation_probability = uniform(0.01, 0.7)\n",
    "    mu = uniform(0.1, 2.5)\n",
    "    sigma = min(uniform(0.1, 1), mu)\n",
    "    arms['%s' % i] = Arm('%s' % i, activation_probability, lambda: normalvariate(mu, sigma))\n",
    "\n",
    "arm_ids = list(arms.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pierwszy bandyta - wybiera losowe ramiona\n",
    "\n",
    "class Random(Bandit):\n",
    "    def __init__(self, bandit_id, arm_ids):\n",
    "        super().__init__(bandit_id, arm_ids)\n",
    "    \n",
    "    def recommend(self, size):\n",
    "        return #...\n",
    "    \n",
    "    def feedback(self, arm_id, payout):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ten bandyta oszukuje - zna mozliwosci kazdego z ramion i wybiera najelpsze - przyda nam sie do porownania\n",
    "\n",
    "class Perfect(Bandit):\n",
    "    def __init__(self, bandit_id, arm_ids, arms):\n",
    "        super().__init__(bandit_id, arm_ids)\n",
    "        self.arms = arms\n",
    "        self.expected_payouts = {}\n",
    "        for arm in arms.values():\n",
    "            self.expected_payouts[arm.arm_id] = self.__find_expected_value(arm.payout_function) * arm.activation_probability\n",
    "        self.arm_ids_sorted_by_expected_payout = [x[0] for x in sorted(self.expected_payouts.items(), key=lambda x: x[1], reverse=True)]\n",
    "\n",
    "    def recommend(self, size):\n",
    "        return self.arm_ids_sorted_by_expected_payout[:size]\n",
    "    \n",
    "    def feedback(self, arm_id, payout):\n",
    "        pass\n",
    "    \n",
    "    def __find_expected_value(self, payout_function, n=100000):\n",
    "        # brzydka, ale skuteczna sztuczka, zeby metoda brute-force znalexc wartosc oczekiwana\n",
    "        return sum([payout_function() for i in range(n)]) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tworzymy liste bandytow do przetestowania\n",
    "\n",
    "bandits = [\n",
    "    Random('random', arm_ids),\n",
    "    Perfect('perfect', arm_ids, arms)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uruchamiamy test\n",
    "\n",
    "runner = Runner(arms, bandits)\n",
    "results = runner.simulate(runs, epochs, recommendation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyniki sumaryczne dla wszystkich epok\n",
    "\n",
    "runner.plot_results(results, runs, epochs, mode='cumulative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyniki per epoka\n",
    "\n",
    "runner.plot_results(results, runs, epochs, mode='average')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 2. - bandyci właściwi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EGreedy(Bandit):\n",
    "    def __init__(self, bandit_id, arm_ids, epsilon):\n",
    "        super().__init__(bandit_id, arm_ids)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        self.recommended_rates = {arm_id: 0 for arm_id in arm_ids}\n",
    "        self.activation_rates = {arm_id: 0 for arm_id in arm_ids}\n",
    "        self.payouts = {arm_id: 0.0 for arm_id in arm_ids}\n",
    "        self.payouts_per_recommendation = {arm_id: 0.0 for arm_id in arm_ids}\n",
    "    \n",
    "    def recommend(self, size):\n",
    "        top_n = [x[0] for x in sorted(self.payouts_per_recommendation.items(), key=lambda x: x[1], reverse=True)][:size]\n",
    "        randomized = copy(self.arm_ids)\n",
    "        shuffle(randomized)\n",
    "        \n",
    "        recommendation = []\n",
    "        \n",
    "        # ...\n",
    "\n",
    "        return recommendation\n",
    "    \n",
    "    def feedback(self, arm_id, payout):\n",
    "        if payout > 0:\n",
    "            self.activation_rates[arm_id] += 1\n",
    "        self.payouts[arm_id] += payout\n",
    "        self.payouts_per_recommendation[arm_id] = self.payouts[arm_id] / self.recommended_rates[arm_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCB(Bandit):\n",
    "    def __init__(self, bandit_id, arm_ids, optimism_weight):\n",
    "        super().__init__(bandit_id, arm_ids)\n",
    "        self.optimism_weight = optimism_weight\n",
    "\n",
    "        self.recommended_rates = {arm_id: 0 for arm_id in arm_ids}\n",
    "        self.activation_rates = {arm_id: 0 for arm_id in arm_ids}\n",
    "        self.payouts = {arm_id: 0.0 for arm_id in arm_ids}\n",
    "        self.payouts_per_recommendation = {arm_id: 0.0 for arm_id in arm_ids}\n",
    "    \n",
    "    def recommend(self, size):\n",
    "        # ...\n",
    "\n",
    "        return recommendation\n",
    "    \n",
    "    def feedback(self, arm_id, payout):\n",
    "        if payout > 0:\n",
    "            self.activation_rates[arm_id] += 1\n",
    "        self.payouts[arm_id] += payout\n",
    "        self.payouts_per_recommendation[arm_id] = self.payouts[arm_id] / self.recommended_rates[arm_id]\n",
    "\n",
    "    def _optimism(self, arm):\n",
    "        return # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThompsonSampling(Bandit):\n",
    "    def __init__(self, bandit_id, arm_ids, reward_multiplier, regret_multiplier):\n",
    "        super().__init__(bandit_id, arm_ids)\n",
    "        self.reward_multiplier = reward_multiplier\n",
    "        self.regret_multiplier = regret_multiplier\n",
    "        self.a = {arm_id: 1 for arm_id in arm_ids}\n",
    "        self.b = {arm_id: 1 for arm_id in arm_ids}\n",
    "    \n",
    "    def recommend(self, size):\n",
    "        # ...\n",
    "        \n",
    "        return recommendation\n",
    "    \n",
    "    def feedback(self, arm_id, payout):\n",
    "        reward = payout * self.reward_multiplier\n",
    "        regret = max(1 - payout, 0) * self.regret_multiplier\n",
    "        self.a[arm_id] += reward\n",
    "        self.b[arm_id] += regret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Część 3. - porównanie bandytów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandits = [\n",
    "    Random('random', arm_ids),\n",
    "    Perfect('perfect', arm_ids, arms)\n",
    "]\n",
    "# nie wahaj sie wybrac innych wartosci parametrow bandytow\n",
    "bandits.extend([EGreedy('egreedy_%s' % epsilon, arm_ids, epsilon) for epsilon in [0.01, 0.05, 0.1, 0.25]])\n",
    "bandits.extend([UCB('ucb_%s' % optimism_weight, arm_ids, optimism_weight) for optimism_weight in [0.01, 0.1, 1, 10]])\n",
    "bandits.extend([ThompsonSampling('ts_%s_%s' % (reward_weight, regret_weight), arm_ids, reward_weight, regret_weight)\n",
    "                for reward_weight, regret_weight in [(1, 1), (10, 1), (1, 10), (10, 10)]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "runner = Runner(arms, bandits)\n",
    "results = runner.simulate(runs, epochs, recommendation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.plot_results(results, runs, epochs, mode='cumulative')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
